W0125 17:35:43.554000 3866404 .venv/lib/python3.12/site-packages/torch/distributed/run.py:803] 
W0125 17:35:43.554000 3866404 .venv/lib/python3.12/site-packages/torch/distributed/run.py:803] *****************************************
W0125 17:35:43.554000 3866404 .venv/lib/python3.12/site-packages/torch/distributed/run.py:803] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0125 17:35:43.554000 3866404 .venv/lib/python3.12/site-packages/torch/distributed/run.py:803] *****************************************
2026-01-25 17:35:56,009 - nanochat.flash_attention - [32m[1mINFO[0m - Flash Attention enabled. Using compiled cuda kernels from flash_attn package.
2026-01-25 17:35:56,013 - nanochat.flash_attention - [32m[1mINFO[0m - Flash Attention enabled. Using compiled cuda kernels from flash_attn package.
2026-01-25 17:35:57,988 - nanochat.common - [32m[1mINFO[0m - Distributed world size: 2
slurmstepd: error: *** JOB 9341 ON gpuh07 CANCELLED AT 2026-01-25T17:42:05 ***
