W0125 17:42:43.693000 3906426 .venv/lib/python3.12/site-packages/torch/distributed/run.py:803] 
W0125 17:42:43.693000 3906426 .venv/lib/python3.12/site-packages/torch/distributed/run.py:803] *****************************************
W0125 17:42:43.693000 3906426 .venv/lib/python3.12/site-packages/torch/distributed/run.py:803] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0125 17:42:43.693000 3906426 .venv/lib/python3.12/site-packages/torch/distributed/run.py:803] *****************************************
2026-01-25 17:42:52,494 - nanochat.flash_attention - [32m[1mINFO[0m - Flash Attention enabled. Using compiled cuda kernels from flash_attn package.
2026-01-25 17:42:52,498 - nanochat.flash_attention - [32m[1mINFO[0m - Flash Attention enabled. Using compiled cuda kernels from flash_attn package.
2026-01-25 17:42:53,969 - nanochat.common - [32m[1mINFO[0m - Distributed world size: 2
slurmstepd: error: *** JOB 9342 ON gpuh07 CANCELLED AT 2026-01-25T17:51:35 ***
