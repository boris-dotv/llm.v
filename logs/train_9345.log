
                                                       █████                █████
                                                      ░░███                ░░███
     ████████    ██████   ████████    ██████   ██████  ░███████    ██████  ███████
    ░░███░░███  ░░░░░███ ░░███░░███  ███░░███ ███░░███ ░███░░███  ░░░░░███░░░███░
     ░███ ░███   ███████  ░███ ░███ ░███ ░███░███ ░░░  ░███ ░███   ███████  ░███
     ░███ ░███  ███░░███  ░███ ░███ ░███ ░███░███  ███ ░███ ░███  ███░░███  ░███ ███
     ████ █████░░████████ ████ █████░░██████ ░░██████  ████ █████░░███████  ░░█████
    ░░░░ ░░░░░  ░░░░░░░░ ░░░░ ░░░░░  ░░░░░░   ░░░░░░  ░░░░ ░░░░░  ░░░░░░░░   ░░░░░
    
Autodetected device type: cuda
GPU: NVIDIA H100 80GB HBM3 | Peak FLOPS (BF16): 9.89e+14
✓ Using Flash Attention 3 (Hopper GPU detected), efficient, new and awesome. 其实用的还是 Flash Attention 2, v2.8.3 版本, 是否有针对 H100 的特定优化待考量.
Vocab size: 32,768
num_layers: 32
model_dim: 2048 (base: 2048, nudge: +0)
num_heads: 16
head_dim: 128
num_kv_heads: 16
